{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Higgs-Charm documentation Welcome to the Higgs-Charm documentation. These pages contain information related to the IIHE-CMS pp\\rightarrow Hc analysis.","title":"Home"},{"location":"#higgs-charm-documentation","text":"Welcome to the Higgs-Charm documentation. These pages contain information related to the IIHE-CMS pp\\rightarrow Hc analysis.","title":"Higgs-Charm documentation"},{"location":"about/","text":"About This is the about page.","title":"About"},{"location":"about/#about","text":"This is the about page.","title":"About"},{"location":"analysis/","text":"This is the page for the Higgs-Charm analysis! That's pretty neat-o!","title":"This is the page for the Higgs-Charm analysis!"},{"location":"analysis/#this-is-the-page-for-the-higgs-charm-analysis","text":"That's pretty neat-o!","title":"This is the page for the Higgs-Charm analysis!"},{"location":"hcnlo/challenges/","text":"Challenges Yukawa couplings of light quarks By default, the Yukawa couplings of the light quarks (uds) are set to zero in the loop_sm model. In fact, I believe that no couplings between the Higgs boson and the light quarks are coded into the model. However, since the light couplings differ only from the heavy couplings in their strength, one could easily copy the code that is already present for the heavy quark Higgs boson vertex.","title":"Challenges"},{"location":"hcnlo/challenges/#challenges","text":"","title":"Challenges"},{"location":"hcnlo/challenges/#yukawa-couplings-of-light-quarks","text":"By default, the Yukawa couplings of the light quarks (uds) are set to zero in the loop_sm model. In fact, I believe that no couplings between the Higgs boson and the light quarks are coded into the model. However, since the light couplings differ only from the heavy couplings in their strength, one could easily copy the code that is already present for the heavy quark Higgs boson vertex.","title":"Yukawa couplings of light quarks"},{"location":"hcnlo/introduction/","text":"Introduction Our goal is to produce a next-to-leading order (NLO) sample of pp \\rightarrow H +\\space\\text{jet} events.","title":"Introduction"},{"location":"hcnlo/introduction/#introduction","text":"Our goal is to produce a next-to-leading order (NLO) sample of pp \\rightarrow H +\\space\\text{jet} events.","title":"Introduction"},{"location":"higgsjet/leading-order/","text":"Leading order Higgs plus jet 1. Flavour contributions 1.1 Leading order diagrams In MadGraph, you can easily define the leading order signal using the following commands: MG5_aMC> generate p p > h j This command generates the Feynman diagrams that contribute to this process. The following diagrams are generated at leading order : If we are working in the five flavour (5F) scheme and if the model parameters allow for non-zero light quark Yukawa couplings, then in principle each flavour apart from the top can appear in these diagrams. A generator-level simulation of 10,000 events yields the following results: Process (including antiquark contribution) \\sigma [pb] \\sigma/\\sigma_\\text{tot} pp \\rightarrow H b 0.52 62.1% pp \\rightarrow H g 0.23 27.8% pp \\rightarrow H c 8.45 \\times 10^{-2} 10.1% pp \\rightarrow H s 3.76 \\times 10^{-4} 0.05% pp \\rightarrow H d 2.89 \\times 10^{-6} <0.1% pp \\rightarrow H u 8.83 \\times 10^{-7} <0.1% In the pp\\rightarrow H q channel, the dominant contribution comes from bottom quarks . The contribution from the light quarks ( u,d,s ) is negligible. Essentially, a leading order Higgs plus jet sample would mainly consist of bottom jets, followed by gluon and finally charm jets. 1.2 Effective coupling In the previous section, we discussed only the tree-level diagrams contributing to pp\\rightarrow H + \\text{jet} . There is however another family of diagrams which will contribute heavily to the Higgs plus jet cross section. All of these diagrams are mediated by a Hgg coupling, which incorporates a quark triangle loop : On the right, the loop has been replaced by an effective vertex , which in practice amounts to integrating out the dominant top quark contribution. If we include this Hgg coupling, then the following diagrams become physical: In MadGraph, these effective vertices are included in the Higgs Effective Theory model. The new family of diagrams contributing to pp\\rightarrow H + \\text{jet} can be generated using the command MG5_aMC> generate p p > h j HIG==1 In this command, we specify that only diagrams with a coupling order HIG exactly equal to 1 should be generated, i.e. the diagrams with a single Hgg vertex. If we only simulate the diagrams which contain such a vertex, we obtain the following flavour distributions: Process (including antiquark contribution) \\sigma [pb] \\sigma/\\sigma_\\text{tot} pp \\rightarrow H g 10.62 74.62% pp \\rightarrow H b 0.18 1.28% pp \\rightarrow H c 0.27 1.92% pp \\rightarrow H s 0.32 2.27% pp \\rightarrow H d 1.08 7.66% pp \\rightarrow H u 1.61 11.42% This time, the light flavours seem to have a significant contribution to the Higgs plus jet cross section. This is because there is no dependence on the Yukawa coupling y_q to weigh down the processes where the Higgs boson appears with a light quark. The up and down quarks are now the dominant quark contributions since they have a high amplitude in the proton PDF. The same reasoning applies to the bottom and charm quark contributions, where the roles have now been reversed: For these diagrams, the charm quark is predicted to appear half again as often as the bottom quark. 1.3 Total leading order cross section If we now simulate every diagram contributing to pp\\rightarrow H+\\text{jet} (including the ones with a Hgg coupling), then we obtain the following results: Process (including antiquark contributihon) \\sigma [pb] \\sigma/\\sigma_\\text{tot} pp \\rightarrow H g 10.62 71.32% pp \\rightarrow H b 0.70 4.70% pp \\rightarrow H c 0.33 2.22% pp \\rightarrow H s 0.32 2.15% pp \\rightarrow H d 1.08 7.25% pp \\rightarrow H u 1.61 10.81%","title":"Leading order"},{"location":"higgsjet/leading-order/#leading-order-higgs-plus-jet","text":"","title":"Leading order Higgs plus jet"},{"location":"higgsjet/leading-order/#1-flavour-contributions","text":"","title":"1. Flavour contributions"},{"location":"higgsjet/leading-order/#11-leading-order-diagrams","text":"In MadGraph, you can easily define the leading order signal using the following commands: MG5_aMC> generate p p > h j This command generates the Feynman diagrams that contribute to this process. The following diagrams are generated at leading order : If we are working in the five flavour (5F) scheme and if the model parameters allow for non-zero light quark Yukawa couplings, then in principle each flavour apart from the top can appear in these diagrams. A generator-level simulation of 10,000 events yields the following results: Process (including antiquark contribution) \\sigma [pb] \\sigma/\\sigma_\\text{tot} pp \\rightarrow H b 0.52 62.1% pp \\rightarrow H g 0.23 27.8% pp \\rightarrow H c 8.45 \\times 10^{-2} 10.1% pp \\rightarrow H s 3.76 \\times 10^{-4} 0.05% pp \\rightarrow H d 2.89 \\times 10^{-6} <0.1% pp \\rightarrow H u 8.83 \\times 10^{-7} <0.1% In the pp\\rightarrow H q channel, the dominant contribution comes from bottom quarks . The contribution from the light quarks ( u,d,s ) is negligible. Essentially, a leading order Higgs plus jet sample would mainly consist of bottom jets, followed by gluon and finally charm jets.","title":"1.1 Leading order diagrams"},{"location":"higgsjet/leading-order/#12-effective-coupling","text":"In the previous section, we discussed only the tree-level diagrams contributing to pp\\rightarrow H + \\text{jet} . There is however another family of diagrams which will contribute heavily to the Higgs plus jet cross section. All of these diagrams are mediated by a Hgg coupling, which incorporates a quark triangle loop : On the right, the loop has been replaced by an effective vertex , which in practice amounts to integrating out the dominant top quark contribution. If we include this Hgg coupling, then the following diagrams become physical: In MadGraph, these effective vertices are included in the Higgs Effective Theory model. The new family of diagrams contributing to pp\\rightarrow H + \\text{jet} can be generated using the command MG5_aMC> generate p p > h j HIG==1 In this command, we specify that only diagrams with a coupling order HIG exactly equal to 1 should be generated, i.e. the diagrams with a single Hgg vertex. If we only simulate the diagrams which contain such a vertex, we obtain the following flavour distributions: Process (including antiquark contribution) \\sigma [pb] \\sigma/\\sigma_\\text{tot} pp \\rightarrow H g 10.62 74.62% pp \\rightarrow H b 0.18 1.28% pp \\rightarrow H c 0.27 1.92% pp \\rightarrow H s 0.32 2.27% pp \\rightarrow H d 1.08 7.66% pp \\rightarrow H u 1.61 11.42% This time, the light flavours seem to have a significant contribution to the Higgs plus jet cross section. This is because there is no dependence on the Yukawa coupling y_q to weigh down the processes where the Higgs boson appears with a light quark. The up and down quarks are now the dominant quark contributions since they have a high amplitude in the proton PDF. The same reasoning applies to the bottom and charm quark contributions, where the roles have now been reversed: For these diagrams, the charm quark is predicted to appear half again as often as the bottom quark.","title":"1.2 Effective coupling"},{"location":"higgsjet/leading-order/#13-total-leading-order-cross-section","text":"If we now simulate every diagram contributing to pp\\rightarrow H+\\text{jet} (including the ones with a Hgg coupling), then we obtain the following results: Process (including antiquark contributihon) \\sigma [pb] \\sigma/\\sigma_\\text{tot} pp \\rightarrow H g 10.62 71.32% pp \\rightarrow H b 0.70 4.70% pp \\rightarrow H c 0.33 2.22% pp \\rightarrow H s 0.32 2.15% pp \\rightarrow H d 1.08 7.25% pp \\rightarrow H u 1.61 10.81%","title":"1.3 Total leading order cross section"},{"location":"higgsjet/next-to-leading-order/","text":"Next-to-leading order Higgs plus jet","title":"Next-to-leading order"},{"location":"higgsjet/next-to-leading-order/#next-to-leading-order-higgs-plus-jet","text":"","title":"Next-to-leading order Higgs plus jet"},{"location":"simulation/repository/","text":"Higgs-Charm repository guide Introduction The Higgs-Charm repository for full-sim MC production can be cloned using the command git clone git@github.com:nbreugel/higgs-charm.git The main functions of this repository are: The production of MadGraph cards which contain the information related to the process of interest. The production and submission of HTCondor scripts which run the CMS Gridpack creation process on the T2B machines. The setup of a pipeline to produce Ultra Legacy 2018 CMS Full-Sim samples. It is also possible to clone this repository into an empty directory by simply passing the path to this directory as an argument to the above command. For example git clone git@github.com:nbreugel/higgs-charm.git /path/to/clean/directory Setting up your process Edit the process configuration file Inside process_cfg.py , you need to fill out all of the necessary fields outlined below to configure the process you want to generate: tag : can be any name used to identify the process. It will be used as a directory name to save the MadGraph cards in addons/cards/ . It is important to remember this tag further along. model_name : here you can pass the exact name of the UFO model you would like to use to calculate the matrix elements for your process. These models can for example be found in the feynrules model database and should be placed in addons/models/ . Some models are already included by default: The dim6top_LO_UFO model, used for the study of top quark physics with Effective Field Theory. The Higgs_Effective_Couplings model, which introduces leading-order Higgs-gluon interactions. The SMEFTsim_general_MwScheme_UFO_v3 model (Standard Model Effective Field Theory). processes : an array of strings, each representing a process you want to generate with Madgraph. These processes will be added together in the proc_card.dat. flavour_scheme : specify here whether you want to use the 4F (massive b, not in the proton pdf) or 5F scheme (massless b, included in the proton pdf). This option only redefines the proton multiparticle! It is therefore your responsibility to make sure the bottom quark mass is set accordingly in your model (preferably in a restriction card). Additionally, make sure you are using a 5F parton distribution function. precision : the order to which you would like to simulate your process. If NLO is specified, your decays need to be handled separately by MadSpin. madspin_commands : if the decays are handled by MadSpin, you can specify the necessary commands here similarly to the processes array. Additionally, there are fields related to the study of EFT operators. If these are not relevant to your process, you can simply state no_reweights in the reweighting_strategy field and leave all other fields empty. operators : an array of EFT operators you want to probe. The names should match exactly those in the parameters.py file in your UFO directory. baseline_values : an array of initial values for the Wilson coefficients of each operator. This defines the baseline scenario to which the reweighting factors will be calculated. The choice of these values is of crucial importance to ensure a proper coverage of the entire phase space. Putting all values to 0 (~SM) will most likely result in a bad coverage in the part of the Phase space where the EFT is expected to be most abundant, resulting in large weights and uncertain predictions of the yields and differential distributions. Properly assigning these values requires careful studies. reweighting_strategy : please choose one of the following options no_reweights : no reweighting is applied individual : each operator is varied individually rnd_scan : a random scan over all operators is performed grid : a rectangular grid of Wilson coefficients is scanned minimal : a tetrahedron-construction of scan points that picks the minimal number of scan points needed for a fit of a given order custom : a custom reweighting scheme is provided by the user Then navigate to the corresponding \"if statement\" and fill out the needed parameters: individual : \" points_individual \" is an array of arrays where in each subarray the user has to manually specify the values of the WCs to be scanned for the corresponding operator (using the same ordering as the \" operators \" variable). rnd_scan : specify in \" n_points \" the number of scan points (NOTE: for N operators you need at least 1 + 2*N + (N*(N-1))/2 scan points to determine the quadratic function of the cross section). Then specify the boundaries for each operator in \" boundaries \". grid : specify in each subarray of \" boundaries_and_npoints \" the lower and upper boundary as well as the number of points to be scanned for each operator. For k points and N operators, a grid of k^N points will be constructed. minimal : specify in each subarray of \" boundaries_minimal_scan \" the lower and upper boundary of each operator. Also the \" order \" of the fitted yield must be given (usually 2, but can be 1 for interference only or larger than 2 for multiple insertions of EFT operators). custom : The user has to manually specify the dictionary \" reweight_dict_tmp_ \" where each key,value pair represents one specific scenario of a given set of WCs. Finally, the SM scenario (all WCs put to 0), will be included by default. The naming convention (when not defining \"custom\" as a reweighting strategy) is defined by the translate_weight_name helper function. It starts with \"rwgt_\", followed by listing all operators with their values. Decimal points are replaced by \"p\" and minus signs by \"min\". Create MadGraph cards for your process The prepare_process.py script will read out the configuration from the process_cfg.py file and construct the following cards in addons/cards/<tag> : run_card.dat proc_card.dat reweight_card.dat customizecards.dat madspin_card.dat To this end, run: python prepare_process.py This will also create a copy of submit_gridpack_template.sh , which will be called submit_gridpack_T2B.sh and for which the chosen tag is correctly inserted in the script. Clone genproductions You only need to run this step once. If you have already cloned genproductions, proceed to the next step For the production of CMS samples, we need the pull the cms-sw/genproductions package from github. To this end, run: source setup_production.sh This will create a new directory called \"genproductions\" alongside your current mcgeneration repository and it will copy all the scripts, models, cards that you need to run your sample production. Since the cards have already been moved to the appropriate directory, you can now proceed to the next page. Move cards to MadGraph working directory After having produced the MadGraph cards, you can move the cards to the genproductions/bin/MadGraph5_aMCatNLO/ directory using the command sh move_cards.sh <TAG> Make sure that you use exactly the same tag as the one you specified in the previous step. Afterwards, you are automatically directed to the genproductions/bin/MadGraph5_aMCatNLO/ directory. Producing a gridpack and launching LHE production NOTE: All of the following steps take place within the genproductions/bin/MadGraph5_aMCatNLO/ directory! Before running the following steps, make sure you have your GRID proxy enabled and exported as a variable so the CMSSW scripts can retrieve it. This can be done by running source setup_proxy.sh Additionally, if you are interested in using the five-flavour scheme where the b and c masses (but not the Yukawa couplings) are set to zero in the no_masses restriction card of the loop_sm model, please run the following command: source loopsm_5F_patch.sh This script adds search and replace commands inside the gridpack_generation.sh script which alter the appropriate restriction card in the freshly installed loop_sm model during the production of the gridpack. Production of your CMS gridpack Gridpacks can be produced by running: python ProduceGridpack_condor.py There are two optional arguments, namely the SCRAM architecture ( --scram_arch ) and the CMSSW version ( --cmssw_version ) that are to be used for the gridpack generation. If these are not given, by default the script takes slc7_amd64_gcc700 and CMSSW_10_2_18 . The above command will create an HTCondor submission script. This can be submitted in order to launch the gridpack creation job. After the job has finished, you should see a tarball in your directory, which holds your gridpack. NOTE: gridpack generation can take several minutes up to several hours, depending on your process and the amount of weights/diagrams that need to be saved. Launch production of LHE files Within the genproductions/bin/MadGraph5_aMCatNLO/ folder, you will see the ProduceLHE_condor.py file. It will create the needed scripts and condor submission configurations to run a parallel production or a chosen number of Les Houches event files (LHE). It contains 6 configurable parameters: --tag : A specific tag name to create log files etc. --gridpack : path to the tarball from the gridpack production --outdir : absolute path to the output directory where the .lhe files will be stored. This has to be a folder with write access and anough storage space. A good example is your personal directory on the T2B PNFS storage system ( /pnfs/iihe/cms/user/$USER/myprocess ). If the directory does not yet exist, the script will try to create it, or it will terminate is it fails to do so. --jobflavour : jobFlavour as described in https://batchdocs.web.cern.ch/local/submit.html . This defines the walltime for each job. --neventstotal : total number of events to simulate. --neventsperjob : number of events per condor job. The number of jobs will be --neventstotal/--neventsperjob (rounded up). Example: python ProduceLHE_condor.py \\ --tag=test \\ --gridpack=./test_slc6_amd64_gcc630_CMSSW_9_3_16_tarball.tar.xz \\ --outdir=/pnfs/cms/store/user/nbreugel/output_dir/ \\ --jobflavour=longlunch \\ --neventstotal=1500000 \\ --neventsperjob=10000 This will now create several files, amongst which is ProduceLHE_condor_<tag>.submit . You can submit this to the HTCondor scheduler by running: condor_submit ProduceLHE_condor_<tag>.submit and you can check the status using condor_q Once all jobs have finished, the output is stored in the outdir in the form of a number of files named \" cmsgrid_final_1.lhe with increasing file numbers. Setting up the next simulation steps If everything went well, you should now have a series of .LHE files in your storage directory. The following steps will deal with the showering and decays of your events, as well as the interactions with the CMS detector and the simulation of the detector response. First, run the setupProd.sh script, providing a tagname for the folder that is about to be created as an argument. For example: source setupProd.sh HcToFourMuons The GEN step This step takes place in the prod_<YOURTAG>/CMSSW_10_6_17_patch1/src directory. The first step is called the generator step or GEN step for short. It uses the previously generated LHE files as input, and outputs a collection of ROOT files containing the showered particles. For testing purposes, this step can be run on a file-per-file basis using cmsRun GEN_cfg.py infile=/PATH/TO/INPUT/FILE.lhe outfile=/PATH/TO/OUTPUT/FILE.root nevents=-1 The value of nevents=-1 is interpreted as a full run over all of the events in the input file. For testing purposes, this value can be set to a lower number to decrease the CPU time. To execute the GEN step on a collection of LHE files, an HTCondor submission script has been prepared and can be found under submit_GEN.py . This script produces a directory containing the HTCondor logs and an HTCondor .submit file. The script takes in several arguments: --config: the configuration file to run (will be GEN_cfg.py for this step) --indir: path to input directory that contains input LesHouches (.lhe) files --outdir: path to output directory in which the .root files will be stored (note that the tag specified later will be appended to this directory name!) --jobflavour: Limit to the duration of the job on condor, as specified here --tag: A tag to specify the name of the working directory and output directory For example: python submit_GEN.py \\ --config=./GEN_cfg.py \\ --indir=/pnfs/iihe/cms/store/user/nbreugel/HcToFourMuons/LHE \\ --outdir=/pnfs/iihe/cms/store/user/nbreugel/HcToFourMuons/GEN \\ --jobflavour=tomorrow \\ --tag=Hc4Mu Before submitting the jobs to HTCondor, make sure you have a valid grid proxy: voms-proxy-init --voms cms --valid 192:00 and additionally, have the variable X509_USER_PROXY point towards the X509 proxy file: export X509_USER_PROXY=$(voms-proxy-info -path) echo $X509_USER_PROXY The RAW step This step takes place in the prod_<YOURTAG>/CMSSW_10_6_17_patch1/src directory. Following the GEN step, one has the run the SIM-DIGI-RAW steps. These are already included in the configuration file RAW_cfg.py . A submission script has been prepared to run in parallel on several LHE files via HTCondor. This script can be found under submit_RAW.py . It can be ran providing the following arguments: --config: the configuration file to run (will be RAW_cfg.py for this step) --indir: path to input directory that contains input GEN (.root) files --outdir: path to output directory in which the .root files will be stored (note that the tag specified later will be appended to this directory name!) --jobflavour: Limit to the duration of the job on condor, as specified here --tag: A tag to specify the name of the working directory and output directory For example: python submit_RAW.py \\ --config=./RAW_cfg.py \\ --indir=/pnfs/iihe/cms/store/user/nbreugel/HcToFourMuons/GEN \\ --outdir=/pnfs/iihe/cms/store/user/nbreugel/HcToFourMuons/RAW \\ --jobflavour=tomorrow \\ --tag=Hc4Mu Make sure your grid proxy is valid before submitting the jobs to HTCondor. This step can take quite a while to run, so a jobflavour=nextweek could be necessary. The HLT step This step takes place in the prod_<YOURTAG>/CMSSW_10_2_16_UL/src directory. Similar to the previous steps, the HLT step is included in the configuration file HLT_cfg.py and can be run in parallel using the python script found under submit_HLT.py . Make sure you are in the appropriate CMSSW environment ( CMSSW_10_2_16_UL ) before running this script. The input files for this step are the HLT (.root) files that were produced previously. For example: python submit_HLT.py \\ --config=./HLT_cfg.py \\ --indir=/pnfs/iihe/cms/store/user/nbreugel/HcToFourMuons/RAW \\ --outdir=/pnfs/iihe/cms/store/user/nbreugel/HcToFourMuons/HLT \\ --jobflavour=tomorrow \\ --tag=Hc4Mu Make sure your grid proxy is valid before submitting the jobs to HTCondor. The MINIAOD step This step takes place in the prod_<YOURTAG>/CMSSW_10_6_17_patch1/src directory. Finally, the RECO-AOD-MINIAOD need to be run in order to obtain a ROOT file ready for physics analysis. This step is included in the configuration file MINIAOD_cfg.py and can be run over several files in parallel using the python script found under submit_MINIAOD.py . The input files for this step are the HLT (.root) files that were produced previously. For example: python submit_MINIAOD.py \\ --config=./MINIAOD_cfg.py \\ --indir=/pnfs/iihe/cms/store/user/nbreugel/HcToFourMuons/HLT \\ --outdir=/pnfs/iihe/cms/store/user/nbreugel/HcToFourMuons/MINIAOD \\ --jobflavour=tomorrow \\ --tag=Hc4Mu","title":"Using the repository"},{"location":"simulation/repository/#higgs-charm-repository-guide","text":"","title":"Higgs-Charm repository guide"},{"location":"simulation/repository/#introduction","text":"The Higgs-Charm repository for full-sim MC production can be cloned using the command git clone git@github.com:nbreugel/higgs-charm.git The main functions of this repository are: The production of MadGraph cards which contain the information related to the process of interest. The production and submission of HTCondor scripts which run the CMS Gridpack creation process on the T2B machines. The setup of a pipeline to produce Ultra Legacy 2018 CMS Full-Sim samples. It is also possible to clone this repository into an empty directory by simply passing the path to this directory as an argument to the above command. For example git clone git@github.com:nbreugel/higgs-charm.git /path/to/clean/directory","title":"Introduction"},{"location":"simulation/repository/#setting-up-your-process","text":"","title":"Setting up your process"},{"location":"simulation/repository/#edit-the-process-configuration-file","text":"Inside process_cfg.py , you need to fill out all of the necessary fields outlined below to configure the process you want to generate: tag : can be any name used to identify the process. It will be used as a directory name to save the MadGraph cards in addons/cards/ . It is important to remember this tag further along. model_name : here you can pass the exact name of the UFO model you would like to use to calculate the matrix elements for your process. These models can for example be found in the feynrules model database and should be placed in addons/models/ . Some models are already included by default: The dim6top_LO_UFO model, used for the study of top quark physics with Effective Field Theory. The Higgs_Effective_Couplings model, which introduces leading-order Higgs-gluon interactions. The SMEFTsim_general_MwScheme_UFO_v3 model (Standard Model Effective Field Theory). processes : an array of strings, each representing a process you want to generate with Madgraph. These processes will be added together in the proc_card.dat. flavour_scheme : specify here whether you want to use the 4F (massive b, not in the proton pdf) or 5F scheme (massless b, included in the proton pdf). This option only redefines the proton multiparticle! It is therefore your responsibility to make sure the bottom quark mass is set accordingly in your model (preferably in a restriction card). Additionally, make sure you are using a 5F parton distribution function. precision : the order to which you would like to simulate your process. If NLO is specified, your decays need to be handled separately by MadSpin. madspin_commands : if the decays are handled by MadSpin, you can specify the necessary commands here similarly to the processes array. Additionally, there are fields related to the study of EFT operators. If these are not relevant to your process, you can simply state no_reweights in the reweighting_strategy field and leave all other fields empty. operators : an array of EFT operators you want to probe. The names should match exactly those in the parameters.py file in your UFO directory. baseline_values : an array of initial values for the Wilson coefficients of each operator. This defines the baseline scenario to which the reweighting factors will be calculated. The choice of these values is of crucial importance to ensure a proper coverage of the entire phase space. Putting all values to 0 (~SM) will most likely result in a bad coverage in the part of the Phase space where the EFT is expected to be most abundant, resulting in large weights and uncertain predictions of the yields and differential distributions. Properly assigning these values requires careful studies. reweighting_strategy : please choose one of the following options no_reweights : no reweighting is applied individual : each operator is varied individually rnd_scan : a random scan over all operators is performed grid : a rectangular grid of Wilson coefficients is scanned minimal : a tetrahedron-construction of scan points that picks the minimal number of scan points needed for a fit of a given order custom : a custom reweighting scheme is provided by the user Then navigate to the corresponding \"if statement\" and fill out the needed parameters: individual : \" points_individual \" is an array of arrays where in each subarray the user has to manually specify the values of the WCs to be scanned for the corresponding operator (using the same ordering as the \" operators \" variable). rnd_scan : specify in \" n_points \" the number of scan points (NOTE: for N operators you need at least 1 + 2*N + (N*(N-1))/2 scan points to determine the quadratic function of the cross section). Then specify the boundaries for each operator in \" boundaries \". grid : specify in each subarray of \" boundaries_and_npoints \" the lower and upper boundary as well as the number of points to be scanned for each operator. For k points and N operators, a grid of k^N points will be constructed. minimal : specify in each subarray of \" boundaries_minimal_scan \" the lower and upper boundary of each operator. Also the \" order \" of the fitted yield must be given (usually 2, but can be 1 for interference only or larger than 2 for multiple insertions of EFT operators). custom : The user has to manually specify the dictionary \" reweight_dict_tmp_ \" where each key,value pair represents one specific scenario of a given set of WCs. Finally, the SM scenario (all WCs put to 0), will be included by default. The naming convention (when not defining \"custom\" as a reweighting strategy) is defined by the translate_weight_name helper function. It starts with \"rwgt_\", followed by listing all operators with their values. Decimal points are replaced by \"p\" and minus signs by \"min\".","title":"Edit the process configuration file"},{"location":"simulation/repository/#create-madgraph-cards-for-your-process","text":"The prepare_process.py script will read out the configuration from the process_cfg.py file and construct the following cards in addons/cards/<tag> : run_card.dat proc_card.dat reweight_card.dat customizecards.dat madspin_card.dat To this end, run: python prepare_process.py This will also create a copy of submit_gridpack_template.sh , which will be called submit_gridpack_T2B.sh and for which the chosen tag is correctly inserted in the script.","title":"Create MadGraph cards for your process"},{"location":"simulation/repository/#clone-genproductions","text":"You only need to run this step once. If you have already cloned genproductions, proceed to the next step For the production of CMS samples, we need the pull the cms-sw/genproductions package from github. To this end, run: source setup_production.sh This will create a new directory called \"genproductions\" alongside your current mcgeneration repository and it will copy all the scripts, models, cards that you need to run your sample production. Since the cards have already been moved to the appropriate directory, you can now proceed to the next page.","title":"Clone genproductions"},{"location":"simulation/repository/#move-cards-to-madgraph-working-directory","text":"After having produced the MadGraph cards, you can move the cards to the genproductions/bin/MadGraph5_aMCatNLO/ directory using the command sh move_cards.sh <TAG> Make sure that you use exactly the same tag as the one you specified in the previous step. Afterwards, you are automatically directed to the genproductions/bin/MadGraph5_aMCatNLO/ directory.","title":"Move cards to MadGraph working directory"},{"location":"simulation/repository/#producing-a-gridpack-and-launching-lhe-production","text":"NOTE: All of the following steps take place within the genproductions/bin/MadGraph5_aMCatNLO/ directory! Before running the following steps, make sure you have your GRID proxy enabled and exported as a variable so the CMSSW scripts can retrieve it. This can be done by running source setup_proxy.sh Additionally, if you are interested in using the five-flavour scheme where the b and c masses (but not the Yukawa couplings) are set to zero in the no_masses restriction card of the loop_sm model, please run the following command: source loopsm_5F_patch.sh This script adds search and replace commands inside the gridpack_generation.sh script which alter the appropriate restriction card in the freshly installed loop_sm model during the production of the gridpack.","title":"Producing a gridpack and launching LHE production"},{"location":"simulation/repository/#production-of-your-cms-gridpack","text":"Gridpacks can be produced by running: python ProduceGridpack_condor.py There are two optional arguments, namely the SCRAM architecture ( --scram_arch ) and the CMSSW version ( --cmssw_version ) that are to be used for the gridpack generation. If these are not given, by default the script takes slc7_amd64_gcc700 and CMSSW_10_2_18 . The above command will create an HTCondor submission script. This can be submitted in order to launch the gridpack creation job. After the job has finished, you should see a tarball in your directory, which holds your gridpack. NOTE: gridpack generation can take several minutes up to several hours, depending on your process and the amount of weights/diagrams that need to be saved.","title":"Production of your CMS gridpack"},{"location":"simulation/repository/#launch-production-of-lhe-files","text":"Within the genproductions/bin/MadGraph5_aMCatNLO/ folder, you will see the ProduceLHE_condor.py file. It will create the needed scripts and condor submission configurations to run a parallel production or a chosen number of Les Houches event files (LHE). It contains 6 configurable parameters: --tag : A specific tag name to create log files etc. --gridpack : path to the tarball from the gridpack production --outdir : absolute path to the output directory where the .lhe files will be stored. This has to be a folder with write access and anough storage space. A good example is your personal directory on the T2B PNFS storage system ( /pnfs/iihe/cms/user/$USER/myprocess ). If the directory does not yet exist, the script will try to create it, or it will terminate is it fails to do so. --jobflavour : jobFlavour as described in https://batchdocs.web.cern.ch/local/submit.html . This defines the walltime for each job. --neventstotal : total number of events to simulate. --neventsperjob : number of events per condor job. The number of jobs will be --neventstotal/--neventsperjob (rounded up). Example: python ProduceLHE_condor.py \\ --tag=test \\ --gridpack=./test_slc6_amd64_gcc630_CMSSW_9_3_16_tarball.tar.xz \\ --outdir=/pnfs/cms/store/user/nbreugel/output_dir/ \\ --jobflavour=longlunch \\ --neventstotal=1500000 \\ --neventsperjob=10000 This will now create several files, amongst which is ProduceLHE_condor_<tag>.submit . You can submit this to the HTCondor scheduler by running: condor_submit ProduceLHE_condor_<tag>.submit and you can check the status using condor_q Once all jobs have finished, the output is stored in the outdir in the form of a number of files named \" cmsgrid_final_1.lhe with increasing file numbers.","title":"Launch production of LHE files"},{"location":"simulation/repository/#setting-up-the-next-simulation-steps","text":"If everything went well, you should now have a series of .LHE files in your storage directory. The following steps will deal with the showering and decays of your events, as well as the interactions with the CMS detector and the simulation of the detector response. First, run the setupProd.sh script, providing a tagname for the folder that is about to be created as an argument. For example: source setupProd.sh HcToFourMuons","title":"Setting up the next simulation steps"},{"location":"simulation/repository/#the-gen-step","text":"This step takes place in the prod_<YOURTAG>/CMSSW_10_6_17_patch1/src directory. The first step is called the generator step or GEN step for short. It uses the previously generated LHE files as input, and outputs a collection of ROOT files containing the showered particles. For testing purposes, this step can be run on a file-per-file basis using cmsRun GEN_cfg.py infile=/PATH/TO/INPUT/FILE.lhe outfile=/PATH/TO/OUTPUT/FILE.root nevents=-1 The value of nevents=-1 is interpreted as a full run over all of the events in the input file. For testing purposes, this value can be set to a lower number to decrease the CPU time. To execute the GEN step on a collection of LHE files, an HTCondor submission script has been prepared and can be found under submit_GEN.py . This script produces a directory containing the HTCondor logs and an HTCondor .submit file. The script takes in several arguments: --config: the configuration file to run (will be GEN_cfg.py for this step) --indir: path to input directory that contains input LesHouches (.lhe) files --outdir: path to output directory in which the .root files will be stored (note that the tag specified later will be appended to this directory name!) --jobflavour: Limit to the duration of the job on condor, as specified here --tag: A tag to specify the name of the working directory and output directory For example: python submit_GEN.py \\ --config=./GEN_cfg.py \\ --indir=/pnfs/iihe/cms/store/user/nbreugel/HcToFourMuons/LHE \\ --outdir=/pnfs/iihe/cms/store/user/nbreugel/HcToFourMuons/GEN \\ --jobflavour=tomorrow \\ --tag=Hc4Mu Before submitting the jobs to HTCondor, make sure you have a valid grid proxy: voms-proxy-init --voms cms --valid 192:00 and additionally, have the variable X509_USER_PROXY point towards the X509 proxy file: export X509_USER_PROXY=$(voms-proxy-info -path) echo $X509_USER_PROXY","title":"The GEN step"},{"location":"simulation/repository/#the-raw-step","text":"This step takes place in the prod_<YOURTAG>/CMSSW_10_6_17_patch1/src directory. Following the GEN step, one has the run the SIM-DIGI-RAW steps. These are already included in the configuration file RAW_cfg.py . A submission script has been prepared to run in parallel on several LHE files via HTCondor. This script can be found under submit_RAW.py . It can be ran providing the following arguments: --config: the configuration file to run (will be RAW_cfg.py for this step) --indir: path to input directory that contains input GEN (.root) files --outdir: path to output directory in which the .root files will be stored (note that the tag specified later will be appended to this directory name!) --jobflavour: Limit to the duration of the job on condor, as specified here --tag: A tag to specify the name of the working directory and output directory For example: python submit_RAW.py \\ --config=./RAW_cfg.py \\ --indir=/pnfs/iihe/cms/store/user/nbreugel/HcToFourMuons/GEN \\ --outdir=/pnfs/iihe/cms/store/user/nbreugel/HcToFourMuons/RAW \\ --jobflavour=tomorrow \\ --tag=Hc4Mu Make sure your grid proxy is valid before submitting the jobs to HTCondor. This step can take quite a while to run, so a jobflavour=nextweek could be necessary.","title":"The RAW step"},{"location":"simulation/repository/#the-hlt-step","text":"This step takes place in the prod_<YOURTAG>/CMSSW_10_2_16_UL/src directory. Similar to the previous steps, the HLT step is included in the configuration file HLT_cfg.py and can be run in parallel using the python script found under submit_HLT.py . Make sure you are in the appropriate CMSSW environment ( CMSSW_10_2_16_UL ) before running this script. The input files for this step are the HLT (.root) files that were produced previously. For example: python submit_HLT.py \\ --config=./HLT_cfg.py \\ --indir=/pnfs/iihe/cms/store/user/nbreugel/HcToFourMuons/RAW \\ --outdir=/pnfs/iihe/cms/store/user/nbreugel/HcToFourMuons/HLT \\ --jobflavour=tomorrow \\ --tag=Hc4Mu Make sure your grid proxy is valid before submitting the jobs to HTCondor.","title":"The HLT step"},{"location":"simulation/repository/#the-miniaod-step","text":"This step takes place in the prod_<YOURTAG>/CMSSW_10_6_17_patch1/src directory. Finally, the RECO-AOD-MINIAOD need to be run in order to obtain a ROOT file ready for physics analysis. This step is included in the configuration file MINIAOD_cfg.py and can be run over several files in parallel using the python script found under submit_MINIAOD.py . The input files for this step are the HLT (.root) files that were produced previously. For example: python submit_MINIAOD.py \\ --config=./MINIAOD_cfg.py \\ --indir=/pnfs/iihe/cms/store/user/nbreugel/HcToFourMuons/HLT \\ --outdir=/pnfs/iihe/cms/store/user/nbreugel/HcToFourMuons/MINIAOD \\ --jobflavour=tomorrow \\ --tag=Hc4Mu","title":"The MINIAOD step"}]}